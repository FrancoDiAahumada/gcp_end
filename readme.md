# ‚õÖ Weather ETL Pipeline - GCP Data Engineering Project

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![GCP](https://img.shields.io/badge/GCP-Cloud%20Platform-orange.svg)](https://cloud.google.com/)
[![Terraform](https://img.shields.io/badge/Terraform-Infrastructure-purple.svg)](https://terraform.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Pipeline ETL serverless en Google Cloud Platform para an√°lisis de datos meteorol√≥gicos en tiempo real**

Un proyecto completo de ingenier√≠a de datos que demuestra la implementaci√≥n de un pipeline ETL moderno usando servicios cloud nativos, infraestructura como c√≥digo y mejores pr√°cticas de DevOps.

---

## üéØ **Objetivo del Proyecto**

Desarrollar un pipeline ETL robusto y escalable que:
- Extraiga datos meteorol√≥gicos de m√∫ltiples ciudades latinoamericanas
- Procese y transforme los datos para an√°lisis
- Automatice la ejecuci√≥n diaria sin intervenci√≥n manual
- Implemente infraestructura versionada y reproducible

---

## üèóÔ∏è **Arquitectura del Sistema**

```mermaid
graph TD
    A[Cloud Scheduler] -->|10:00 diario| B[Pub/Sub Topic]
    B --> C[Cloud Function: Extract]
    C --> D[OpenWeather API]
    C --> E[Cloud Storage - Raw Data]
    C --> F[BigQuery - raw_weather]
    
    E -->|Trigger| G[Cloud Function: Transform]
    G --> H[BigQuery - clean_weather]
    
    style A fill:#4285f4,stroke:#333,color:#fff
    style C fill:#34a853,stroke:#333,color:#fff
    style G fill:#ea4335,stroke:#333,color:#fff
    style H fill:#fbbc04,stroke:#333,color:#000
```

### **Componentes Principales**

| Servicio | Funci√≥n | Tecnolog√≠a |
|----------|---------|------------|
| **Cloud Scheduler** | Automatizaci√≥n temporal | Cron Jobs |
| **Pub/Sub** | Mensajer√≠a as√≠ncrona | Event-driven |
| **Cloud Functions** | Procesamiento serverless | Python 3.9+ |
| **Cloud Storage** | Data Lake (raw data) | JSON files |
| **BigQuery** | Data Warehouse | SQL analytics |
| **Terraform** | Infrastructure as Code | HCL |

---

## üìä **Datos Procesados**

### **Ciudades Monitoreadas**
- üá®üá± Santiago, Chile
- üá¶üá∑ Buenos Aires, Argentina
- üáµüá™ Lima, Per√∫
- üá®üá¥ Bogot√°, Colombia
- üá™üá® Quito, Ecuador
- üá∫üáæ Montevideo, Uruguay

### **M√©tricas Capturadas**
```json
{
  "city": "Santiago",
  "temperature": 22.5,
  "humidity": 65,
  "pressure": 1013.25,
  "wind_speed": 3.2,
  "weather_condition": "Clear",
  "timestamp": "2025-07-23T10:00:00Z"
}
```

---

## üöÄ **Flujo de Datos Detallado**

### **1. Extracci√≥n (Extract Function)**
```python
# Proceso de extracci√≥n diario
‚îú‚îÄ‚îÄ Conexi√≥n a OpenWeather API
‚îú‚îÄ‚îÄ Iteraci√≥n por ciudades configuradas
‚îú‚îÄ‚îÄ Validaci√≥n y limpieza inicial
‚îú‚îÄ‚îÄ Almacenamiento en Cloud Storage (raw/YYYY-MM-DD/)
‚îî‚îÄ‚îÄ Inserci√≥n en BigQuery (raw_weather table)
```

### **2. Transformaci√≥n (Transform Function)**
```python
# Proceso de transformaci√≥n
‚îú‚îÄ‚îÄ Lectura desde raw_weather
‚îú‚îÄ‚îÄ Limpieza y normalizaci√≥n de datos
‚îú‚îÄ‚îÄ C√°lculo de m√©tricas derivadas
‚îú‚îÄ‚îÄ Validaci√≥n de calidad de datos
‚îî‚îÄ‚îÄ Inserci√≥n en clean_weather table
```

### **3. Automatizaci√≥n**
- ‚è∞ **Frecuencia**: Diaria a las 10:00 AM (UTC-3)
- üîÑ **Tolerancia a fallos**: Reintentos autom√°ticos
- üìä **Monitoreo**: Logs centralizados en Cloud Logging

---

## üìÅ **Estructura del Proyecto**

```
weather-etl-pipeline/
‚îú‚îÄ‚îÄ üìÇ .github/workflows/          # CI/CD con GitHub Actions
‚îÇ   ‚îî‚îÄ‚îÄ deploy.yml
‚îú‚îÄ‚îÄ üìÇ extract_function/           # Funci√≥n de extracci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ üìÇ transform_function/         # Funci√≥n de transformaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ utils.py
‚îú‚îÄ‚îÄ üìÇ terraform/                  # Infrastructure as Code
‚îÇ   ‚îú‚îÄ‚îÄ main.tf
‚îÇ   ‚îú‚îÄ‚îÄ variables.tf
‚îÇ   ‚îú‚îÄ‚îÄ terraform.tfvars.example
‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf
‚îÇ   ‚îî‚îÄ‚îÄ versions.tf
‚îú‚îÄ‚îÄ üìÇ tests/                      # Pruebas unitarias
‚îÇ   ‚îú‚îÄ‚îÄ test_extract.py
‚îÇ   ‚îî‚îÄ‚îÄ test_transform.py
‚îú‚îÄ‚îÄ üìÇ docs/                       # Documentaci√≥n t√©cnica
‚îú‚îÄ‚îÄ üìÑ requirements.txt
‚îú‚îÄ‚îÄ üìÑ .gitignore
‚îú‚îÄ‚îÄ üìÑ LICENSE
‚îî‚îÄ‚îÄ üìÑ README.md
```

---

## ‚öôÔ∏è **Instalaci√≥n y Despliegue**

### **Prerrequisitos**
```bash
# Herramientas necesarias
- Google Cloud SDK (gcloud)
- Terraform >= 1.0
- Python 3.9+
- Git
```

### **1. Configuraci√≥n Inicial**
```bash
# Clonar el repositorio
git clone https://github.com/franco-ahumada/weather-etl-pipeline.git
cd weather-etl-pipeline

# Configurar variables de entorno
cp terraform/terraform.tfvars.example terraform/terraform.tfvars
# Editar terraform.tfvars con tus valores
```

### **2. Despliegue con Terraform**
```bash
cd terraform

# Inicializar Terraform
terraform init

# Planificar cambios
terraform plan

# Aplicar infraestructura
terraform apply
```

### **3. Configuraci√≥n de API Keys**
```bash
# Configurar OpenWeather API Key
gcloud functions deploy weather-extract \
  --set-env-vars OPENWEATHER_API_KEY=your_api_key_here
```

---

## üìà **Casos de Uso**

### **Para Data Engineers**
- Implementaci√≥n de pipeline ETL serverless
- Uso de servicios cloud nativos
- Infrastructure as Code con Terraform
- Event-driven architecture

### **Para Data Analysts**
- Datos meteorol√≥gicos hist√≥ricos estructurados
- An√°lisis de tendencias clim√°ticas regionales
- Dashboards y visualizaciones
- APIs para consumo de datos

### **Para DevOps Engineers**
- CI/CD con GitHub Actions
- Monitoreo y alertas
- Gesti√≥n de secretos
- Automatizaci√≥n de despliegues

---

## üìä **Consultas de Ejemplo**

### **Temperatura promedio por ciudad (√∫ltimos 30 d√≠as)**
```sql
SELECT 
  city,
  AVG(temperature) as avg_temp,
  COUNT(*) as records
FROM `your-project.weather_analytics.clean_weather`
WHERE date >= DATE_SUB(CURRENT_DATE(), INTERVAL 30 DAY)
GROUP BY city
ORDER BY avg_temp DESC;
```

### **Ciudades con mayor variabilidad t√©rmica**
```sql
SELECT 
  city,
  STDDEV(temperature) as temp_variance,
  MIN(temperature) as min_temp,
  MAX(temperature) as max_temp
FROM `your-project.weather_analytics.clean_weather`
WHERE date >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)
GROUP BY city
ORDER BY temp_variance DESC;
```

---

## üîß **Configuraci√≥n Avanzada**

<details>
<summary><strong>Variables de Terraform</strong></summary>

```hcl
# terraform/terraform.tfvars
project_id = "your-gcp-project-id"
region = "us-central1"
bucket_name = "your-weather-data-bucket"
dataset_id = "weather_analytics"
api_key_secret = "openweather-api-key"

# Ciudades a monitorear
cities = [
  "Santiago,CL",
  "Buenos Aires,AR",
  "Lima,PE",
  "Bogot√°,CO"
]
```
</details>

<details>
<summary><strong>Monitoreo y Alertas</strong></summary>

```yaml
# .github/workflows/monitoring.yml
name: Pipeline Health Check
on:
  schedule:
    - cron: '0 11 * * *'  # Verificar 1 hora despu√©s del ETL

jobs:
  health_check:
    runs-on: ubuntu-latest
    steps:
      - name: Check BigQuery Data Freshness
        run: |
          # Script para verificar que los datos del d√≠a est√°n presentes
```
</details>

---

## üö® **Troubleshooting**

### **Errores Comunes**

| Error | Causa | Soluci√≥n |
|-------|-------|----------|
| `403 Forbidden` | API Key inv√°lida | Verificar OPENWEATHER_API_KEY |
| `409 Conflict` | Recurso ya existe | Usar `terraform import` |
| `Timeout` | Funci√≥n excede 540s | Optimizar consultas BigQuery |

### **Comandos de Diagn√≥stico**
```bash
# Ver logs de Cloud Functions
gcloud functions logs read weather-extract --limit 50

# Verificar estado de Pub/Sub
gcloud pubsub topics list

# Validar datos en BigQuery
bq query --use_legacy_sql=false 'SELECT COUNT(*) FROM weather_analytics.clean_weather WHERE date = CURRENT_DATE()'
```

---

## üéØ **Pr√≥ximas Mejoras**

- [ ] **Dashboard en Looker Studio** para visualizaci√≥n de datos
- [ ] **Alertas autom√°ticas** para condiciones meteorol√≥gicas extremas
- [ ] **ML Pipeline** para predicci√≥n del clima
- [ ] **API REST** para consumo externo de datos
- [ ] **Tests de integraci√≥n** con pytest
- [ ] **Documentaci√≥n OpenAPI** para endpoints

---

## ü§ù **Contribuciones**

Las contribuciones son bienvenidas! Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -m 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

---

## üìÑ **Licencia**

Este proyecto est√° bajo la Licencia MIT. Ver el archivo [LICENSE](LICENSE) para m√°s detalles.

---

## üë®‚Äçüíª **Autor**

**Franco Ahumada** - *Data Engineer*

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?style=flat&logo=linkedin)](https://linkedin.com/in/franco-ahumada)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-black?style=flat&logo=github)](https://github.com/franco-ahumada)
[![Portfolio](https://img.shields.io/badge/Portfolio-Visit-green?style=flat&logo=web)](https://franco-ahumada.dev)

---

## ‚≠ê **Stack Tecnol√≥gico**

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Google Cloud](https://img.shields.io/badge/Google_Cloud-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)
![Terraform](https://img.shields.io/badge/Terraform-623CE4?style=for-the-badge&logo=terraform&logoColor=white)
![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-2088FF?style=for-the-badge&logo=github-actions&logoColor=white)
![BigQuery](https://img.shields.io/badge/BigQuery-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)

---

<div align="center">
  <strong>üåü Si este proyecto te resulta √∫til, no olvides darle una estrella! üåü</strong>
</div>