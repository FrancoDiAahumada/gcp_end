# Weather ETL Pipeline en GCP â˜”ï¸ğŸš€

Este proyecto construye un pipeline de ExtracciÃ³n, TransformaciÃ³n y Carga (ETL) en Google Cloud Platform para recolectar datos meteorolÃ³gicos desde la API de OpenWeather, almacenarlos en formato crudo y luego procesarlos para su anÃ¡lisis.

---

## ğŸŒ TecnologÃ­as utilizadas

* **Google Cloud Functions**: para ejecutar cÃ³digo de extracciÃ³n y transformaciÃ³n
* **Google Cloud Storage**: para almacenar los datos en formato JSON (data lake)
* **Google BigQuery**: para consultas y almacenamiento estructurado
* **Google Pub/Sub**: para disparar eventos entre componentes
* **Google Cloud Scheduler**: para automatizar la ejecuciÃ³n diaria
* **Terraform**: para definir la infraestructura como cÃ³digo
* **Git/GitHub**: para versionar el cÃ³digo del proyecto

---

## ğŸ  Arquitectura del pipeline

```
 Cloud Scheduler
      â¬‡
   Pub/Sub Topic
      â¬‡
+----------------------------+
|  Cloud Function: extract  | -----> Almacena datos en Cloud Storage (raw) y BigQuery (raw_weather)
+----------------------------+
                                      â¬‡
                         +-----------------------------+
                         | Cloud Function: transform   | -----> Crea tabla clean_weather en BigQuery
                         +-----------------------------+
```

---

## ğŸš€ Flujo del ETL

1. **ExtracciÃ³n:**

   * API: OpenWeather
   * Ciudades: Santiago, Buenos Aires, Lima, BogotÃ¡, etc.
   * Datos obtenidos: temperatura, humedad, presiÃ³n, viento, etc.

2. **Almacenamiento crudo:**

   * Cloud Storage (estructura: `raw/daily/YYYY-MM-DD/*.json`)
   * BigQuery (tabla: `raw_weather`)

3. **TransformaciÃ³n:**

   * Limpieza de campos, estructuras, y preparaciÃ³n para anÃ¡lisis
   * Tabla resultante: `clean_weather`

4. **AutomatizaciÃ³n:**

   * Cloud Scheduler ejecuta todos los dÃ­as a las 10:00 (hora Santiago)
   * Pub/Sub dispara la ejecuciÃ³n de ambas funciones

---

## ğŸ“ Estructura del repositorio

```
weather-function/
â”œâ”€â”€ dags/                    # DAGs para Apache Airflow (opcional)
â”œâ”€â”€ extract_function/       # CÃ³digo de extracciÃ³n
â”œâ”€â”€ transform_function/    # CÃ³digo de transformaciÃ³n
â”œâ”€â”€ terraform/             # Infraestructura como cÃ³digo
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ variables.tf
â”‚   â”œâ”€â”€ terraform.tfvars
â”‚   â””â”€â”€ outputs.tf
â””â”€â”€ README.md
```

---

## âœ… Despliegue con Terraform

```bash
cd terraform
terraform init
terraform plan
terraform apply
```

> Si los recursos ya existen en GCP, se pueden importar para evitar errores 409:

```bash
terraform import google_bigquery_dataset.weather_dataset your-project-id:weather_analytics
terraform import google_storage_bucket.weather_data_bucket your-bucket-name
terraform import google_pubsub_topic.weather_topic projects/your-project-id/topics/weather-trigger
```

---

## ğŸš€ Estado actual del proyecto

* [x] ExtracciÃ³n y carga a Cloud Storage y BigQuery
* [x] TransformaciÃ³n de datos en BigQuery
* [x] AutomatizaciÃ³n con Pub/Sub + Scheduler
* [x] Infraestructura definida y versionada con Terraform
* [ ] Agregar dashboards o visualizaciones (prÃ³ximo paso)

---

## ğŸ¤ ContribuciÃ³n y uso

Este repositorio estÃ¡ pensado como referencia y formaciÃ³n para roles de Data Engineer Junior. Puedes adaptarlo, escalarlo, y versionarlo para proyectos reales.

---

## ğŸš€ Autor

Franco Ahumada - 2025
Stack actual: Python â­ GCP â­ Terraform â­ GitHub CI CD
